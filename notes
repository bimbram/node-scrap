Lesson 7. The Request library method
-What it is doing?
1. The simplest way of doing HTTP(s) requests
2. You can send GET, POST, PUT, DELETE, and more types of requests
3. Supports HTTP Basic Auth, Gzip, multipart-data post, custom headers, file streaming.. And a lot more

-Pro's & Con's
1. PRO - You control each request and every parameter
2. PRO - Very fast (compared to a headless browser)
3. CON - It can get messy if not done right
4. CON - You could potentially write more code (compared to a headless browser)

-When to use it?
1. Is API based
2. Has basic authentication
3. Is NOT dynamically rendered
4. Downloading files

Lesson 6. Running with Terminal CMD & Basics on VSCode Debugger
-Just a simple instruction how to debug in VSCode

Lesson 5. The biggest problem with scraping
-Maintenance & Stability
1. Everything work fine until it doesn't, it can work for one day then it can fail (because the website can change)

-How can you solve this?
1. You can't, you need to debug and fix it

Lesson 4. Why & When to Choose Scraping
-Why we want to scrape a website?
1. It can be more convenient
2. You could get more data out
3. You do not have an official api
4. You have a shitty official api

-When to scrape a website?
1. The website does not specifically say that it is not ok to scrape it
2. You get permission from the owner of the website / company

-Advice & Conclusion
1. Respect the ToS (terms of service) of the website that you want to scrape
2. Use the official API's where possible
3. Do not over do it, make sure to not bombard their website with request
4. Seek legal advice from a lawyer if you want to be 100% sure about a website, in case you want to be serious and you rely on that data

Lesson 3. Writing a Simple IMDB Scraper
-Finished creating the project
